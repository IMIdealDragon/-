# 排序算法

 [TOC]

![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\fb8394a588b12ff6695cfd664afb17cd.jpg)

 ![è¿éåå¾çæè¿°](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\SouthEast)  

**插入排序和冒泡排序的时间复杂度相同，都是 O(n2)，在实际的软件开发里，为什么我们更倾向于使用插入排序算法而不是冒泡排序算法呢？**

一般来说，数据量比较小的时候用插入或者选择，数据量比较大的时候用快速排序或者归并排序。如果不是要求全部有序，而是要有序的第几个，比如topk这种问题一般是堆排序。

## 逆序度——排序目标量化

对于包含 n 个数据的数组，这 n 个数据就有 n! 种排列方式。不同的排列方式，冒泡排序执行的时间肯定是不同的。比如我们前面举的那两个例子，其中一个要进行 6 次冒泡，而另一个只需要 4 次。如果用概率论方法定量分析平均时间复杂度，涉及的数学推理和计算就会很复杂。**我这里还有一种思路，通过“有序度”和“逆序度”这两个概念来进行分析。**

有序度是数组中具有有序关系的元素对的个数。有序元素对用数学表达式表示就是这样：

> 有序元素对：a[i] <= a[j], 如果i < j。

 ![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\a1ef4cc1999d6bd0af08d8417ee55220.jpg) 

同理，对于一个倒序排列的数组，比如 6，5，4，3，2，1，有序度是 0；对于一个完全有序的数组，比如 1，2，3，4，5，6，有序度就是 **n*(n-1)/2**，也就是 15。我们把这种**完全有序的数组的有序度叫作满有序度**。

关于这三个概念，我们还可以得到一个公式：**逆序度 = 满有序度 - 有序度**。**我们排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，就说明排序完成了。**

所以排序算法的最坏情况就是有序度为0，这样需要 **n*(n-1)/2**操作，就是o(n2),如果平均情况，可以取有序度为n*(n-1)/4

## 如何分析一个“排序算法”？

### 排序算法的执行效率

#### 1.最好情况、最坏情况、平均情况时间复杂度

我们在分析排序算法的时间复杂度时，要分别给出最好情况、最坏情况、平均情况下的时间复杂度。除此之外，你还要说出最好、最坏时间复杂度对应的要排序的原始数据是什么样的。为什么要区分这三种时间复杂度呢？第一，有些排序算法会区分，为了好对比，所以我们最好都做一下区分。第二，对于要排序的数据，有的接近有序，有的完全无序。有序度不同的数据，对于排序的执行时间肯定是有影响的，我们要知道排序算法在不同数据下的性能表现。

#### 2. 时间复杂度的系数、常数、低阶

我们知道，时间复杂度反应的是数据规模 n 很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低阶。但是实际的软件开发中，我们排序的可能是 **10 个、100 个、1000** 个这样规模很小的数据，所以，在对同一阶时间复杂度的排序算法性能对比的时候，我们就要把**系数、常数、低阶**也考虑进来

#### 3. 比较次数和交换（或移动）次数

基于比较的排序算法的执行过程，会涉及两种操作，**一种是元素比较大小，另一种是元素交换或移动**。所以，如果我们在分析排序算法的执行效率的时候，**应该把比较次数和交换（或移动）次数也考虑进去**。

### 排序算法的内存消耗

我们前面讲过，算法的内存消耗可以通过空间复杂度来衡量，排序算法也不例外。不过，针对排序算法的空间复杂度，我们还引入了一个新的概念，原地排序（Sorted in place）。**原地排序算法，就是特指空间复杂度是 O(1) 的排序算法**。我们今天讲的三种排序算法，都是原地排序算法。

### 排序算法的稳定性

仅仅用执行效率和内存消耗来衡量排序算法的好坏是不够的。针对排序算法，我们还有一个重要的度量指标，稳定性。这个概念是说，如果待排序的序列中存在值相等的元素，经过排序之后，**相等元素之间原有的先后顺序不变**。

## 冒泡排序

冒泡排序只会操作**相邻的两个数据**。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。

我用一个例子，带你看下冒泡排序的整个过程。我们要对一组数据 4，5，6，3，2，1，从小到大进行排序。第一次冒泡操作的详细过程就是这样：

 ![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\4038f64f47975ab9f519e4f739e464e9.jpg)

 实际上，刚讲的冒泡过程还可以优化。当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。我这里还有另外一个例子，这里面给 6 个元素排序，只需要 4 次冒泡操作就可以了

 ![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\a9783a3b13c11a5e064c5306c261e8e6.jpg) 

```cpp
void bubbleSort(int a[], int n)
{
    if(n <= 1) return ;
    for(int i = n; i > 0; --i)/*排序的趟数*/
    {
        bool flag = false;/*每次设置交换标识为0*/
        for(int j = 0; j < i; ++j)/*本趟排序的遍历元素个数*/
        {
            if(a[j] > a[j+1])
            {
                swap(a[j], a[j+1]);
                flag = true;
            }
                
        }
        /*本趟数，无数据交换的话，说明已经有序，直接退出*/
        if(false == flag)
            return ;
    }
}
```

**利用有序度分析**：要排序的数组的初始状态是 4，5，6，3，2，1 ，其中，有序元素对有 (4，5) (4，6)(5，6)，所以有序度是 3。n=6，所以排序完成之后终态的满有序度为 n*(n-1)/2=15。

**结论：冒泡空间复杂度O（1），是原地排序，前后元素相等则不交换，因此是稳定的，时间复杂度是O（n2）**

## 插入排序（优化：希尔排序）

我们先来看一个问题。一个有序的数组，我们往里面添加一个新的数据后，如何继续保持数据有序呢？很简单，我们只要遍历数组，找到数据应该插入的位置将其插入即可。

 这是一个动态排序的过程，即动态地往有序集合中添加数据，我们可以通过这种方法保持集合中的数据一直有序。而对于一组静态数据，我们也可以借鉴上面讲的插入方法，来进行排序，于是就有了插入排序算法。 

**那插入排序具体是如何借助上面的思想来实现排序的呢？**

如图所示，要排序的数据是 4，5，6，1，3，2，其中左侧为**已排序区间**，右侧是**未排序区间**。

插入算法的核心思想是**取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序**。重复这个过程，直到未排序区间中元素为空，算法结束。

 ![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\b60f61ec487358ac037bf2b6974d2de1.jpg) 

插入排序也包含两种操作，一种是**元素的比较**，一种是**元素的移动**。当我们需要将一个数据 a 插入到已排序区间时，需要拿 a 与已排序区间的元素依次比较大小，找到合适的插入位置。找到插入点之后，我们还需要将插入点之后的元素顺序往后移动一位，这样才能腾出位置给元素 a 插入。

对于不同的查找插入点方法（从头到尾、从尾到头），元素的比较次数是有区别的。但对于一个给定的初始序列，移动操作的次数总是固定的，就等于逆序度。

```cpp
void insertSort(int a[], int n)
{
    if(n <= 1) return ;
    for(int i = 1; i < n; ++i)//从第二个元素开始取
    {
       	int value = a[i];//要插入的元素
        int j = i - 1;
        for(; j >= 0; --j) {
            if(a[j] > value) { //当前元素大于插入的元素，移动位置
                a[j + 1] = a[j];//数据移动
            }
            else //当前元素小于插入的元素，说明要插在这个后面
                break;
        }
        
        a[j + 1] = value;
    }
}
```

**结论：空间复杂度为O(1)，排序稳定，时间复杂度平均最坏：O（n2），最好O(n)**

### Q：冒泡排序和插入排序的时间复杂度都是 O(n2)，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？

从代码实现上来看，冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序需要 3 个赋值操作，而插入排序只需要 1 个。

## 选择排序

选择排序算法的实现思路有点类似插入排序，也分**已排序区间**和**未排序区间**。但是选择排序每次会从**未排序区间中找到最小的元素，将其放到已排序区间的末尾**。

 ![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\32371475a0b08f0db9861d102474181d.jpg) 

```cpp
void selectSort(int a[], int n)
{
    if(n <= 1) return;
    for(int i = 0;i < n; ++i)
    {
        int min = i;
        for(int j = i + 1; j < n; ++j)//找出未排序部分的最小值，和未排序的第一个元素交换
        {
            if(a[j] < a[min])
                min = j;
        }
        
        if(min != i)
            swap(a[i], a[min]);
    }
}
```

**结论：选择排序空间复杂度为 O(1)，是一种原地排序算法。选择排序的最好情况时间复杂度、最坏情况和平均情况时间复杂度都为 O(n2)。选择排序是不稳定的，因为每次都要找未排序中的最小值并和第一个元素交换，破坏了稳定性，举例：比如 5，8，5，2，9 这样一组数据，使用选择排序算法来排序的话，第一次找到最小元素 2，与第一个 5 交换位置，那第一个 5 和中间的 5 顺序就变了，所以就不稳定了。正是因此，相对于冒泡排序和插入排序，选择排序就稍微逊色了**

### Q: 特定算法是依赖特定的数据结构的。我们今天讲的几种排序算法，都是基于数组实现的。如果数据存储在链表中，这三种排序算法还能工作吗？如果能，那相应的时间、空间复杂度又是多少呢？

 对于老师所提课后题，觉得应该有个前提，是否允许修改链表的节点value值，还是只能改变节点的位置。一般而言，考虑只能改变节点位置，冒泡排序相比于数组实现，比较次数一致，但交换时操作更复杂；插入排序，比较次数一致，不需要再有后移操作，找到位置后可以直接插入，但排序完毕后可能需要倒置链表；选择排序比较次数一致，交换操作同样比较麻烦。综上，时间复杂度和空间复杂度并无明显变化，若追求极致性能，冒泡排序的时间复杂度系数会变大，插入排序系数会减小，选择排序无明显变化。 

---------------------------------------------------------------------------------------------------------------------------------------------------------

上一节我讲了**冒泡排序、插入排序、选择排序**这三种排序算法，它们的时间复杂度都是 O(n2)，比较高，适合**小规模数据的排序**。今天，我讲两种时间复杂度为 O(nlogn) 的排序算法，**归并排序和快速排序**。这两种排序算法适合**大规模的数据排序**，比上一节讲的那三种排序算法要更常用。

## 归并排序

归并排序的核心思想还是蛮简单的。**如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了**。

 ![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\db7f892d3355ef74da9cd64aa926dc2b.jpg) 

```cpp
// 归并排序算法模板
void merge_sort(int q[], int l, int r)
{
    if (l >= r) return;
    
    int mid = l + r >> 1;
    merge_sort(q, l, mid);
    merge_sort(q, mid + 1, r);
    
    int k = 0, i = l, j = mid + 1;
    while (i <= mid && j <= r)
        if (q[i] < q[j]) tmp[k ++ ] = q[i ++ ];
        else tmp[k ++ ] = q[j ++ ];
    
    while (i <= mid) tmp[k ++ ] = q[i ++ ];
    while (j <= r) tmp[k ++ ] = q[j ++ ];
    
    for (i = l, j = 0; i <= r; i ++, j ++ ) q[i] = tmp[j];
}
```

**结论：稳定，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)，空间复杂度是 O(n)。**

## 快速排序

快排的思想是这样的：**如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。根据分治、递归的处理思想，我们可以用递归排序下标从 p 到 q-1 之间的数据和下标从 q+1 到 r 之间的数据，直到区间缩小为 1，就说明所有的数据都有序了。**

 ![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\4d892c3a2e08a17f16097d07ea088a81.jpg) 

```cpp
void quick_sort(int a[], int n)
{
    if (a <= 1) return;
    int l = 0, r = n - 1;
    int i = l - 1, j = r + 1, x = a[l];
    while (i < j)
    {
        do i ++ ; while (a[i] < x);
        do j -- ; while (a[j] > x);
        if (i < j) swap(a[i], a[j]);
        else break;
    }
    quick_sort(a, l, j), quick_sort(a, j + 1, r);
}
```

**结论：快排是一种原地、不稳定的排序算法， 快排的时间复杂度也是 O(nlogn) 。**

### Q：快排和归并用的都是分治思想，递推公式和递归代码也非常相似，那它们的区别在哪里呢？

 ![img](D:\A_目标！！！\algorithm\algorithm-learning\review\pic\aa03ae570dace416127c9ccf9db8ac05.jpg) 

可以发现，归并排序的处理过程是**由下到上的**，先处理子问题，然后再合并。而快排正好相反，它的处理过程是**由上到下的**，先分区，然后再处理子问题。归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法。我们前面讲过，归并之所以是非原地排序算法，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。

### Q：O(n) 时间复杂度内求无序数组中的第 K 大元素

我们选择数组区间 A[0…n-1] 的最后一个元素 A[n-1] 作为 pivot，对数组 A[0…n-1] 原地分区，这样数组就分成了三部分，A[0…p-1]、A[p]、A[p+1…n-1]。如果 p+1=K，那 A[p] 就是要求解的元素；如果 K>p+1, 说明第 K 大元素出现在 A[p+1…n-1] 区间，我们再按照上面的思路递归地在 A[p+1…n-1] 这个区间内查找。同理，如果 K<p+1，那我们就在 A[0…p-1] 区间查找。

### Q：现在你有 10 个接口访问日志文件，每个日志文件大小约 300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这 10 个较小的日志文件，合并为 1 个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有 1GB，你有什么好的解决思路，能“快速”地将这 10 个日志文件合并吗？

 每次从各个文件中取一条数据，在内存中根据数据时间戳构建一个最小堆，然后每次把最小值给写入新文件，同时将最小值来自的那个文件再出来一个数据，加入到最小堆中。这个空间复杂度为常数，但没能很好利用1g内存，而且磁盘单个读取比较慢，所以考虑每次读取一批数据，没了再从磁盘中取，时间复杂度还是一样O(n)。

 先构建十条io流，分别指向十个文件，每条io流读取对应文件的第一条数据，然后比较时间戳，选择出时间戳最小的那条数据，将其写入一个新的文件，然后指向该时间戳的io流读取下一行数据，然后继续刚才的操作，比较选出最小的时间戳数据，写入新文件，io流读取下一行数据，以此类推，完成文件的合并， 这种处理方式，日志文件有n个数据就要比较n次，每次比较选出一条数据来写入，时间复杂度是O（n），空间复杂度是O（1）,几乎不占用内存，这是我想出的认为最好的操作了，希望老师指出最佳的做法！！！ 

 我觉得最后的思考题，[曹源]同学的策略是较优的。
该策略的最大好处是充分利用了内存。
但是我还是会这么做：
1.申请10个40M的数组和一个400M的数组。
2.每个文件都读40M，取各数组中最大时间戳中的最小值。
3.然后利用二分查找，在其他数组中快速定位到小于/等于该时间戳的位置，并做标记。
4.再把各数组中标记位置之前的数据全部放在申请的400M内存中，
5.在原来的40M数组中清除已参加排序的数据。[可优化成不挪动数据，只是用两个索引标记有效数据的起始和截止位置]
6.对400M内存中的有效数据[没装满]做快排。
将排好序的直接写文件。
7.再把每个数组尽量填充满。从第2步开始继续，知道各个文件都读区完毕。
这么做的好处有：
1.每个文件的内容只读区一次，且是批量读区。比每次只取一条快得多。
2.充分利用了读区到内存中的数据。曹源 同学在文件中查找那个中间数是会比较困难的。
3.每个拷贝到400M大数组中参加快排的数据都被写到了文件中，这样每个数只参加了一次快排。 

